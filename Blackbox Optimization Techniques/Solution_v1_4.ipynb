{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Solution v1.4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwrO12pf3cTz"
      },
      "source": [
        "# Project 3 - Black-Box Policy Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lflXMl-D3Yn6"
      },
      "source": [
        "### Import the environment from the course website\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqkHRKCT3YwK",
        "outputId": "8763175d-beb3-4145-80e6-6ad1b07fbdd5"
      },
      "source": [
        "!wget  -q https://sites.google.com/a/g.clemson.edu/cpsc-drl/assignments/hw3/project3.zip\r\n",
        "!unzip -q project3.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace frogger_env/agent/frogger_agent.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dY1pwIRdMXOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed10ec1-aaf4-4bde-fa88-43f3b5586798"
      },
      "source": [
        "!apt-get update\r\n",
        "!apt-get install xvfb\r\n",
        "!apt-get install x11-utils\r\n",
        "!apt-get install ffmpeg\r\n",
        "!apt-get install python-opengl \r\n",
        "!pip -q install gym pyvirtualdisplay pygame\r\n",
        "!pip3 install box2d-py\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"ENVIRONMENT\"\"\"\r\n",
        "import gym                                                                      #OpenAI gym \r\n",
        "import frogger_env\r\n",
        "gym.logger.set_level(40)                                                        #suppresses warning messages, displays only error messages\r\n",
        "\r\n",
        "\"\"\"MODELS AND TOOLS FOR OPTIMIZATION AND OTHER COMPUTATIONS\"\"\"\r\n",
        "import time\r\n",
        "import numpy as np\r\n",
        "import torch                                                                    #will use PyTorch to handle the NN \r\n",
        "import torch.nn as nn                                                           #contains various NN layers\r\n",
        "import torch.nn.functional as F                                                 #includes various functions such as convolution etc.\r\n",
        "import torch.optim as optim                                                     #contains various optimization algorithms\r\n",
        "import random\r\n",
        "from random import sample\r\n",
        "from collections import deque\r\n",
        "\r\n",
        "\"\"\"VISUALIZATION\"\"\"\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "from IPython import display as ipythondisplay\r\n",
        "from pyvirtualdisplay import Display\r\n",
        "from gym.wrappers import Monitor\r\n",
        "import base64\r\n",
        "\r\n",
        "\"\"\"I/O\"\"\"\r\n",
        "import os\r\n",
        "from pathlib import Path"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 252 kB in 2s (120 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.8).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "x11-utils is already the newest version (7.7+3build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.7/dist-packages (2.3.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX26ge7C3nDw"
      },
      "source": [
        "### Display for visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V_9FNC3JKH_"
      },
      "source": [
        "display=Display(visible=0, size=(600, 400))\r\n",
        "display.start()\r\n",
        "\r\n",
        "#Define a simple helper function to visualize the episodes\r\n",
        "def show_video(path):\r\n",
        "    html = []\r\n",
        "    for mp4 in Path(path).glob(\"*.mp4\"):\r\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\r\n",
        "        html.append('''<video alt=\"{}\" autoplay \r\n",
        "                      controls style=\"height: 400px;\">\r\n",
        "                      <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\r\n",
        "                 </video>'''.format(mp4, video_b64.decode('ascii')))\r\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHB73giw3p72"
      },
      "source": [
        "###Testing things out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "XB43Ai86JTT6",
        "outputId": "6ccb53ef-a4be-4900-871e-060bcb73718a"
      },
      "source": [
        "env = gym.make(\"CartPole-v0\")\r\n",
        "env = Monitor(env, './video', force=True, video_callable=lambda episode: True)\r\n",
        "env.reset()\r\n",
        "done = False\r\n",
        "while not done:\r\n",
        "    action = 1\r\n",
        "    obs, reward, done, info = env.step(action)\r\n",
        "env.close()\r\n",
        "show_video('./video')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"video/openaigym.video.0.59.video000000.mp4\" autoplay \n",
              "                      controls style=\"height: 400px;\">\n",
              "                      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "                 </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJckGLox3vJY"
      },
      "source": [
        "The observation that the agent receives is its position, the goal position, and a unit vector that points from the agent's position to the goal.\r\n",
        "\r\n",
        "The action space consists of four actions 0: move up, 1: move down, 2: move right 3: move left"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-WeT91LJV-E",
        "outputId": "6cd1f11e-ca89-4e07-cb00-3c9b1c9d83b1"
      },
      "source": [
        "print('observation space:', env.observation_space)\r\n",
        "print('action space:', env.action_space)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (4,), float32)\n",
            "action space: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA4NzGIe31ND"
      },
      "source": [
        "###Some useful functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGr_AmdO34aV"
      },
      "source": [
        "from google.colab import drive\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "def save_checkpoint(model, filename, mode=0):\r\n",
        "    \"\"\"\r\n",
        "    Save a model to a file in your colab space \r\n",
        "        \r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    model: your policy network\r\n",
        "    filename: the name of the checkpoint file\r\n",
        "    mode (int): determines where to store the file\r\n",
        "                --> 0: collab space 1: Google Drive\r\n",
        "    \"\"\"\r\n",
        "    if mode == 1: \r\n",
        "      drive.mount('/content/gdrive')\r\n",
        "      path = F\"/content/gdrive/My Drive/{filename}\" \r\n",
        "      torch.save(model.state_dict(), path)\r\n",
        "    else:\r\n",
        "      torch.save(model.state_dict(), filename)\r\n",
        "\r\n",
        "def export_to_local_drive(filename):\r\n",
        "    \"\"\"\r\n",
        "    Download a file to your local machine \r\n",
        "        \r\n",
        "    Parameters\r\n",
        "    ----------\r\n",
        "    filename: the name of the file\r\n",
        "    \"\"\"\r\n",
        "    files.download(filename)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65VB-bZ037hz"
      },
      "source": [
        "###Cross Entropy Method\r\n",
        "Implement below the cross-entropy method to solve the reacher-v0 environment and enable the agent to learn to navigate to a fixed goal position on a static highway map. Please, refer to the project descriprtion and lecture 13 for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGOZAN4EMnWZ",
        "outputId": "7eaab53d-2375-447b-a45a-e0f91b43febf"
      },
      "source": [
        "from scipy.stats import norm\r\n",
        "\"\"\"SWITCH TO A GPU IF ONE IS AVAILABLE\"\"\"\r\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"DEFINITION OF THE ARCHITECTURE AND THE ATTRIBUTES OF THE NEURAL NETWORK\"\"\"\r\n",
        "class network(nn.Module):\r\n",
        "  def __init__(self,observations,actions,hu1,hu2,hu3):\r\n",
        "    super(network, self).__init__()\r\n",
        "    self.l1=nn.Linear(observations,hu1)                                         #layer1 is a fully-connected layer with #I/P=observations and #hidden units=hu1\r\n",
        "    self.l2=nn.Linear(hu1,actions)                                              #layer2 is a fully-connected layer with #I/P=hu1 and #hidden units=actions\r\n",
        "    #self.l3=nn.Linear(hu2,actions)\r\n",
        "    #initialize interconnection weights and bias weights using a probability\r\n",
        "    #distribution (code below is for a normal distribution with μ=0 and σ=1)\r\n",
        "    #nn.init.normal_(self.l1.weight.data,mean=0,std=1)\r\n",
        "    #nn.init.normal_(self.l1.bias.data,mean=0,std=1)\r\n",
        "    #nn.init.normal_(self.l2.weight.data,mean=0,std=1)\r\n",
        "    #nn.init.normal_(self.l2.bias.data,mean=0,std=1)\r\n",
        "    #nn.init.normal_(self.l3.weight.data,mean=0,std=1)\r\n",
        "    #nn.init.normal_(self.l3.bias.data,mean=0,std=1)\r\n",
        "\r\n",
        "  def forward(self, x):                                                         #forward propagation function\r\n",
        "    if not isinstance(x,torch.Tensor):                                          #check if the I/P is a tensor or not\r\n",
        "      x=torch.tensor(x,device=device,dtype=torch.float32)                       #convert the I/P to a tensor and move it to 'device'\r\n",
        "      x=x.unsqueeze(0)\r\n",
        "    x=F.relu(self.l1(x))\r\n",
        "    #x=F.relu(self.l2(x))\r\n",
        "    x=F.tanh(self.l2(x))\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"DEFINITION OF THE CHARACTERISTICS AND ATTRIBUTES OF THE CEM AGENT\"\"\"\r\n",
        "class CEMagent():\r\n",
        "  def __init__(self,observations,actions,hu1,hu2,hu3):\r\n",
        "    self.policynet=network(observations,actions,hu1,hu2,hu3).to(device)         #define a policy-network object of type 'network', initialize its weights θ randomly and move it to the GPU\r\n",
        "    self.tempnet=network(observations,actions,hu1,hu2,hu3).to(device)           #define a dummy netowrk object of type 'network', initialize its weights θ randomly and move it to the GPU\r\n",
        "\r\n",
        "  def train(self, env,seed,gamma,mean,sigma,n,k,maxIterations):\r\n",
        "    self.gamma=gamma\r\n",
        "    self.mean=mean\r\n",
        "    self.sigma=sigma\r\n",
        "    self.dimension=sum(p.numel() for p in self.policynet.parameters())\r\n",
        "    torch.manual_seed(seed) \r\n",
        "    np.random.seed(seed)\r\n",
        "    random.seed(seed)\r\n",
        "    env.seed(seed)\r\n",
        "    self.evalScoreIteration=[]                                                  #stores evaluation score at the end of each weigth update\r\n",
        "    iterations=0\r\n",
        "    while iterations<maxIterations:\r\n",
        "      iterations+=1      \r\n",
        "      theta_is=[]                                                               #stores all perturbations of θ\r\n",
        "      for i in range(n):                                                        #run this loop 'n' times to collect 'n' perturbations of θ\r\n",
        "        theta_is.append(self.perturbations())\r\n",
        "      G_is=self.rollOut(env,theta_is)                                           #call this function to perform a roll-out corresponding to each θ, and calculate the corresponding reward R(τi)\r\n",
        "      indices=np.argsort(G_is)[-k:].tolist()                                    #extract indices of the highest k% of Gi where Gi=R(τi)\r\n",
        "      theta_is=[theta_is[index] for index in indices]                           #use the extracted indices to identify the corresponding θi\r\n",
        "      self.weightUpdate(theta_is)                                               #update the weights of the policy network using the identifed θi \r\n",
        "      evalScore=self.evaluate(env)                                              #perform a roll-out after each round of weight update            \r\n",
        "      self.evalScoreIteration.append(evalScore)      \r\n",
        "      print('Iteration#: {:d}\\tEvaluation reward: {:.2f}\\tMean evaluation reward: {:.2f}\\tSTD of evaluation reward: {:.2f}'.format(iterations,evalScore,np.mean(self.evalScoreIteration),np.std(self.evalScoreIteration)))\r\n",
        "      if np.mean(self.evalScoreIteration)>=160.0 and iterations!=1:\r\n",
        "        break\r\n",
        "    return self.evalScoreIteration\r\n",
        "\r\n",
        "  def perturbations(self):\r\n",
        "    temp=torch.cat([parameter.view(-1) for parameter in self.policynet.parameters()])\r\n",
        "    perturbation=temp+(self.mean+(self.sigma*torch.randn(self.dimension).to(device)))\r\n",
        "    return perturbation\r\n",
        "\r\n",
        "  def rollOut(self,env,theta_is):\r\n",
        "    R=[]                                                                        #list stores R(τi) of each τi\r\n",
        "    for i in theta_is:\r\n",
        "      temp=self.tempnet.state_dict()\r\n",
        "      theta_i=torch.tensor(i).to(device)\r\n",
        "      lLimit,hLimit=0,0\r\n",
        "      for label,parameter in zip(temp,self.tempnet.parameters()):               #iterate over each label of 'temp' and each parameter of the policy network\r\n",
        "        hLimit=lLimit+sum(p.numel() for p in temp[label])\r\n",
        "        temp[label]=torch.reshape(theta_i[lLimit:hLimit],temp[label].size())    #generate a perturbation of the current parameter using the expression θ=θ+σε\r\n",
        "        lLimit=hLimit\r\n",
        "      self.tempnet.load_state_dict(temp)\r\n",
        "      terminal=False\r\n",
        "      numExperiences=0\r\n",
        "      s=env.reset()\r\n",
        "      R.append(0.0)\r\n",
        "      while not terminal:\r\n",
        "        s=torch.tensor(s).type(torch.FloatTensor).to(device)\r\n",
        "        with torch.no_grad():\r\n",
        "          Q=self.tempnet(s).cpu().detach().data.numpy().squeeze()\r\n",
        "        action=np.argmax(Q)\r\n",
        "        sP,r,terminal,info=env.step(action)\r\n",
        "        s=sP\r\n",
        "        numExperiences+=1\r\n",
        "        R[-1]+=(self.gamma**(numExperiences-1))*r                               #sum of discounted rewards of the current trajectory\r\n",
        "    return R\r\n",
        "\r\n",
        "  def weightUpdate(self,theta_is):                                              #this function updates the weights of the policy network\r\n",
        "    temp=self.policynet.state_dict()                                            #create a copy of the weights of the policy network\r\n",
        "    for label,parameter in zip(temp,self.policynet.parameters()):               #iterate over each label of 'temp' and each parameter of the policy network\r\n",
        "      temp[label]=torch.zeros_like(parameter)                                   #initialize all weights to zeros\r\n",
        "    for i in theta_is:                                                          #loop over each selected θi\r\n",
        "      theta_i=torch.tensor(i).to(device)                                        #convert selected θi to tensor\r\n",
        "      lLimit,hLimit=0,0\r\n",
        "      for label in temp:                                                        #loop over each label of 'temp'\r\n",
        "        hLimit=lLimit+sum(parameter.numel() for parameter in temp[label])\r\n",
        "        temp[label]+=torch.reshape(theta_i[lLimit:hLimit],temp[label].size())   #add current component of current θi to the corresponding component of 'temp'\r\n",
        "        lLimit=hLimit\r\n",
        "    for label in temp:                                                          #loop over all labels of 'temp' and calculate the average of each element in its components\r\n",
        "      temp[label]/=len(theta_is)\r\n",
        "    self.policynet.load_state_dict(temp)\r\n",
        "\r\n",
        "  def evaluate(self,env,rollOuts=1):                                            #this function performs a fixed #roll-outs at the end of each training episode and evaluates the associated rewards\r\n",
        "    rewards=[]\r\n",
        "    for rollOut in range(rollOuts):\r\n",
        "      rewards.append(0.0)\r\n",
        "      s1=env.reset()\r\n",
        "      terminal1=False\r\n",
        "      numExperiences=0\r\n",
        "      while not terminal1:\r\n",
        "        s1=torch.tensor(s1).float().to(device)\r\n",
        "        a1=self.greedy(s1)\r\n",
        "        s1,r1,terminal1,info1=env.step(a1)\r\n",
        "        numExperiences+=1\r\n",
        "        rewards[-1]+=(self.gamma**(numExperiences-1))*r1\r\n",
        "    return np.mean(rewards)\r\n",
        "\r\n",
        "  def greedy(self,s):                                                           #this function returns the action that is greedy wrt to the Q-values of the state 's'\r\n",
        "    with torch.no_grad():\r\n",
        "      Q=self.policynet(s)\r\n",
        "    Q=Q.cpu().numpy()\r\n",
        "    return np.argmax(Q)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"DEFINE THE ENVIRONMENT, THE PARAMETERS OF THE AGENT AND THE HYPERPARAMETERS\r\n",
        "OF THE NEURAL NETWORK\"\"\"\r\n",
        "env=gym.make('CartPole-v0')                                                      #declare the environment variable\r\n",
        "hu1=16                                                                          #size of the first hidden layer of the NN\r\n",
        "hu2=10                                                                          #size of the second hidden layer of the NN\r\n",
        "hu3=5\r\n",
        "gamma=1                                                                       #the discount factor\r\n",
        "maxIterations=2000                                                              #maximum iterations for which is θ updated\r\n",
        "seed=6                                                                          #random seed used for random initialization of the network weights, the environment and various random function\r\n",
        "sigma=.1                                                                        #standard deviation for perturbing θ\r\n",
        "mean=.01                                                                        #mean for perturbing θ\r\n",
        "n=100                                                                           ##perturbations of θ\r\n",
        "k=20                                                                            #select the best k% θi from θ\r\n",
        "meanReward100=env.spec.reward_threshold                                         #mean reward earned over the last 100 episodes\r\n",
        "observations=env.observation_space.shape[0]                                     ##observations or I/P features\r\n",
        "actions=env.action_space.n                                                      #actions\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"CEM\"\"\"\r\n",
        "env.seed(seed)                                                                  #set the seed for the environment\r\n",
        "agent=CEMagent(observations,actions,hu1,hu2,hu3)                                #create an object of type 'CEMagent'\r\n",
        "result=agent.train(env,seed,gamma,mean,sigma,n,k,maxIterations)                 #train the CEM agent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:76: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1628: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration#: 1\tEvaluation reward: 47.00\tMean evaluation reward: 47.00\tSTD of evaluation reward: 0.00\n",
            "Iteration#: 2\tEvaluation reward: 132.00\tMean evaluation reward: 89.50\tSTD of evaluation reward: 42.50\n",
            "Iteration#: 3\tEvaluation reward: 55.00\tMean evaluation reward: 78.00\tSTD of evaluation reward: 38.32\n",
            "Iteration#: 4\tEvaluation reward: 70.00\tMean evaluation reward: 76.00\tSTD of evaluation reward: 33.37\n",
            "Iteration#: 5\tEvaluation reward: 126.00\tMean evaluation reward: 86.00\tSTD of evaluation reward: 35.93\n",
            "Iteration#: 6\tEvaluation reward: 137.00\tMean evaluation reward: 94.50\tSTD of evaluation reward: 37.91\n",
            "Iteration#: 7\tEvaluation reward: 172.00\tMean evaluation reward: 105.57\tSTD of evaluation reward: 44.35\n",
            "Iteration#: 8\tEvaluation reward: 110.00\tMean evaluation reward: 106.12\tSTD of evaluation reward: 41.51\n",
            "Iteration#: 9\tEvaluation reward: 200.00\tMean evaluation reward: 116.56\tSTD of evaluation reward: 49.01\n",
            "Iteration#: 10\tEvaluation reward: 200.00\tMean evaluation reward: 124.90\tSTD of evaluation reward: 52.81\n",
            "Iteration#: 11\tEvaluation reward: 200.00\tMean evaluation reward: 131.73\tSTD of evaluation reward: 54.78\n",
            "Iteration#: 12\tEvaluation reward: 200.00\tMean evaluation reward: 137.42\tSTD of evaluation reward: 55.74\n",
            "Iteration#: 13\tEvaluation reward: 200.00\tMean evaluation reward: 142.23\tSTD of evaluation reward: 56.09\n",
            "Iteration#: 14\tEvaluation reward: 200.00\tMean evaluation reward: 146.36\tSTD of evaluation reward: 56.06\n",
            "Iteration#: 15\tEvaluation reward: 200.00\tMean evaluation reward: 149.93\tSTD of evaluation reward: 55.79\n",
            "Iteration#: 16\tEvaluation reward: 200.00\tMean evaluation reward: 153.06\tSTD of evaluation reward: 55.36\n",
            "Iteration#: 17\tEvaluation reward: 200.00\tMean evaluation reward: 155.82\tSTD of evaluation reward: 54.83\n",
            "Iteration#: 18\tEvaluation reward: 200.00\tMean evaluation reward: 158.28\tSTD of evaluation reward: 54.24\n",
            "Iteration#: 19\tEvaluation reward: 200.00\tMean evaluation reward: 160.47\tSTD of evaluation reward: 53.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldxCqeI_wmDN"
      },
      "source": [
        "###Test the policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZ_nVmzPwmr4"
      },
      "source": [
        "\"\"\"TESTING\"\"\"\r\n",
        "env=gym.make('CartPole-v0')\r\n",
        "env=Monitor(env,'./video',force=True,video_callable=lambda episode:True)\r\n",
        "#env.seed(10)\r\n",
        "s=env.reset()\r\n",
        "terminal=False\r\n",
        "episodeReward=0\r\n",
        "while not terminal:\r\n",
        "  s=torch.tensor(s).float().to(device)\r\n",
        "  a=agent.greedy(s)\r\n",
        "  s,r,terminal,info=env.step(a)\r\n",
        "  episodeReward+=r\r\n",
        "env.close()\r\n",
        "print('\\nEpisode reward:'+str(episodeReward))\r\n",
        "show_video('./video')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pl-6614Yx-A4"
      },
      "source": [
        "###Q1. Cross Entropy Method with Adaptive Exploration\r\n",
        "Implement below the cross-entropy method to solve the reacher-v0 environment and enable the agent to learn to navigate to a fixed goal position on a static highway map. Please, refer to the project descriprtion and lecture 13 for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "q4yFcF8Ex81c",
        "outputId": "f8871117-1fd4-4cfe-fe78-e515fed1170a"
      },
      "source": [
        "from scipy.stats import norm\r\n",
        "\"\"\"SWITCH TO A GPU IF ONE IS AVAILABLE\"\"\"\r\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"DEFINITION OF THE ARCHITECTURE AND THE ATTRIBUTES OF THE NEURAL NETWORK\"\"\"\r\n",
        "class network(nn.Module):\r\n",
        "  def __init__(self,observations,actions,hu1,hu2,hu3):\r\n",
        "    super(network, self).__init__()\r\n",
        "    self.l1=nn.Linear(observations,hu1)                                         #layer1 is a fully-connected layer with #I/P=observations and #hidden units=hu1\r\n",
        "    self.l2=nn.Linear(hu1,actions)                                              #layer2 is a fully-connected layer with #I/P=hu1 and #output units=actions\r\n",
        "    #initialize interconnection weights and bias weights using a probability\r\n",
        "    #distribution (code below is for a normal distribution with μ=0 and σ=1)\r\n",
        "    #nn.init.normal_(self.l1.weight.data,mean=0,std=1)\r\n",
        "    #nn.init.normal_(self.l1.bias.data,mean=0,std=1)\r\n",
        "    #nn.init.normal_(self.l2.weight.data,mean=0,std=1)\r\n",
        "    #nn.init.normal_(self.l2.bias.data,mean=0,std=1)\r\n",
        "    #nn.init.normal_(self.l3.weight.data,mean=0,std=1)\r\n",
        "    #nn.init.normal_(self.l3.bias.data,mean=0,std=1)\r\n",
        "\r\n",
        "  def forward(self,x):                                                          #forward propagation function\r\n",
        "    if not isinstance(x,torch.Tensor):                                          #check if the I/P is a tensor or not\r\n",
        "      x=torch.tensor(x,device=device,dtype=torch.float32)                       #convert the I/P to a tensor and move it to 'device'\r\n",
        "      x=x.unsqueeze(0)\r\n",
        "    x=F.relu(self.l1(x))\r\n",
        "    x=self.l2(x)\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"DEFINITION OF THE CHARACTERISTICS AND ATTRIBUTES OF THE CEM AGENT\"\"\"\r\n",
        "class CEMagent():\r\n",
        "  def __init__(self,observations,actions,hu1,hu2,hu3):\r\n",
        "    self.policynet=network(observations,actions,hu1,hu2,hu3).to(device)         #define a policy-network object of type 'network', initialize its weights θ randomly and move it to the GPU\r\n",
        "    self.tempnet=network(observations,actions,hu1,hu2,hu3).to(device)           #define a dummy netowrk object of type 'network', initialize its weights θ randomly and move it to the GPU\r\n",
        "\r\n",
        "  def train(self,env,seed,mean,sigma,gamma,n,k,maxIterations):\r\n",
        "    self.gamma=gamma\r\n",
        "    self.steps=0                                                                #stores the total #time-steps (or experiences) collected during the training process\r\n",
        "    self.dimension=sum(p.numel() for p in self.policynet.parameters())          #total #interconnection weights of the NN\r\n",
        "    self.mean=mean*torch.ones(self.dimension)                                   #initial mean is a vector of dimension 'self.dimension with all elements being equal to 'mean'\r\n",
        "    self.sigma=sigma*torch.ones(self.dimension)                                 #initial std is a vector of dimension 'self.dimension with all elements being equal to 'sigma'\r\n",
        "    torch.manual_seed(seed) \r\n",
        "    np.random.seed(seed)\r\n",
        "    random.seed(seed)\r\n",
        "    env.seed(seed)\r\n",
        "    self.evalScoreIteration=[]                                                  #stores the evaluation score of each roll-out\r\n",
        "    self.results=[]                                                             #stores the results tuple\r\n",
        "    iterations=0\r\n",
        "    while iterations<maxIterations:\r\n",
        "      iterations+=1\r\n",
        "      theta_is=[]                                                               #stores all perturbations θi\r\n",
        "      for i in range(n):                                                        #run this loop 'n' times to collect 'n' perturbations of θ\r\n",
        "        theta_is.append(self.perturbations())\r\n",
        "      G_is=self.rollOut(env,theta_is)                                           #call this function to perform a roll-out corresponding to each θ, and calculate the corresponding reward Gi=R(τi)\r\n",
        "      indices=np.argsort(G_is)[-k:].tolist()                                    #extract indices of the highest k% of Gi where Gi=R(τi)\r\n",
        "      theta_is=[theta_is[index] for index in indices]                           #use the extracted indices to identify the corresponding θi\r\n",
        "      self.weightUpdate(theta_is,k)                                             #update the weights of the policy network\r\n",
        "      self.fit(theta_is)                                                        #call this function to fit a new distribution to the selected best θi\r\n",
        "      evalScore=self.evaluate(env)                                              #perform a roll-out after each round of weight update            \r\n",
        "      self.evalScoreIteration.append(evalScore)      \r\n",
        "      print('Iteration#: {:d}\\tStep#: {:d}\\tEvaluation reward: {:.2f}\\tMean evaluation reward: {:.2f}\\tSTD of evaluation reward: {:.2f}'.format(iterations,self.steps,evalScore,np.mean(self.evalScoreIteration),np.std(self.evalScoreIteration)))\r\n",
        "      self.results.append((iterations,self.steps,evalScore,np.mean(self.evalScoreIteration),np.std(self.evalScoreIteration)))\r\n",
        "      if np.mean(self.evalScoreIteration)>=1.2 and iterations!=1:               #break the algorithm if the mean reward over all roll-outs exceeds 1.2\r\n",
        "        break\r\n",
        "    return self.results,self.policynet\r\n",
        "\r\n",
        "  def perturbations(self):                                                      #this function generates perturbations θi\r\n",
        "    perturbation=self.mean+(self.sigma*torch.randn(self.dimension))\r\n",
        "    return perturbation\r\n",
        "\r\n",
        "  def rollOut(self,env,theta_is):                                               #this function executes one roll-out for each θi and collects the corresponding reward R(τi)\r\n",
        "    R=[]                                                                        #list stores R(τi) of each τi\r\n",
        "    temp=self.tempnet.state_dict()\r\n",
        "    for i in theta_is:\r\n",
        "      theta_i=torch.tensor(i).to(device)                                        #as θi is not a tensor, make it one and move it to the GPU\r\n",
        "      lLimit,hLimit=0,0                                                         #these two variables form the upper and lower limit of weight slices\r\n",
        "      for label,parameter in zip(temp,self.tempnet.parameters()):               #iterate over each label of 'temp' and each parameter of the policy network\r\n",
        "        hLimit=lLimit+sum(p.numel() for p in temp[label])\r\n",
        "        temp[label]=torch.reshape(theta_i[lLimit:hLimit],temp[label].size())    #generate a perturbation of the current parameter using the expression θ=θ+σε\r\n",
        "        lLimit=hLimit\r\n",
        "      self.tempnet.load_state_dict(temp)                                        #use θi as the weight of 'tempnet' and use the latter to execute a roll-out\r\n",
        "      terminal=False\r\n",
        "      numExperiences=0\r\n",
        "      s=env.reset()\r\n",
        "      R.append(0.0)\r\n",
        "      while not terminal:                                                       #run the episode until it terminates\r\n",
        "        self.steps+=1                                                           #each step in the episode is considered as one time-step (or experience)\r\n",
        "        s=torch.tensor(s).type(torch.FloatTensor).to(device)\r\n",
        "        with torch.no_grad():\r\n",
        "          Q=self.tempnet(s).cpu().detach().data.numpy().squeeze()\r\n",
        "        action=np.argmax(Q)\r\n",
        "        sP,r,terminal,info=env.step(action)\r\n",
        "        s=sP\r\n",
        "        numExperiences+=1\r\n",
        "        R[-1]+=(self.gamma**(numExperiences-1))*r                               #sum of discounted rewards of the current trajectory (or episode)\r\n",
        "    return R\r\n",
        "\r\n",
        "  def weightUpdate(self,theta_is,k):                                            #this function updates the weights of the policy network\r\n",
        "    temp=self.policynet.state_dict()                                            #create a copy of the weights of the policy network\r\n",
        "    for label,parameter in zip(temp,self.policynet.parameters()):               #iterate over each label of 'temp' and each parameter of the policy network\r\n",
        "      temp[label]=torch.zeros_like(parameter)                                   #initialize all weights to zeros\r\n",
        "    for i in theta_is:                                                          #loop over each selected θi\r\n",
        "      theta_i=torch.tensor(i).to(device)                                        #convert selected θi to tensor and move it to the GPU\r\n",
        "      lLimit,hLimit=0,0                                                         #these two variables form the upper and lower limit of weight slices\r\n",
        "      for label in temp:                                                        #loop over each label of 'temp'\r\n",
        "        hLimit=lLimit+sum(parameter.numel() for parameter in temp[label])\r\n",
        "        temp[label]+=torch.reshape(theta_i[lLimit:hLimit],temp[label].size())   #add current component of current θi to the corresponding component of 'temp'\r\n",
        "        lLimit=hLimit\r\n",
        "    for label in temp:                                                          #loop over all labels of 'temp' and calculate the average of each element in its components\r\n",
        "      temp[label]/=k\r\n",
        "    self.policynet.load_state_dict(temp)                                        #replace the weights of the policy network θ with the new weight θnew\r\n",
        "\r\n",
        "  def fit(self,theta_is):                                                       #this function fits a distribution to the selected best θi\r\n",
        "    temp=torch.stack(theta_is)\r\n",
        "    self.mean=torch.mean(temp,0)\r\n",
        "    self.sigma=torch.std(temp,0)\r\n",
        "\r\n",
        "  def evaluate(self,env,rollOuts=1):                                            #this function performs a fixed #roll-outs at the end of each training episode and evaluates the associated rewards\r\n",
        "    rewards=[]\r\n",
        "    for rollOut in range(rollOuts):\r\n",
        "      rewards.append(0.0)\r\n",
        "      s1=env.reset()\r\n",
        "      terminal1=False\r\n",
        "      numExperiences=0\r\n",
        "      while not terminal1:                                                      #run the episode until it terminates\r\n",
        "        s1=torch.tensor(s1).float().to(device)\r\n",
        "        a1=self.greedy(s1)\r\n",
        "        s1,r1,terminal1,info1=env.step(a1)\r\n",
        "        numExperiences+=1\r\n",
        "        rewards[-1]+=(self.gamma**(numExperiences-1))*r1\r\n",
        "    return np.mean(rewards)\r\n",
        "\r\n",
        "  def greedy(self,s):                                                           #this function returns the action that is greedy wrt to the Q-values of the state 's'\r\n",
        "    with torch.no_grad():\r\n",
        "      Q=self.policynet(s)\r\n",
        "    Q=Q.cpu().numpy()\r\n",
        "    return np.argmax(Q)\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"DEFINE THE ENVIRONMENT, THE PARAMETERS OF THE AGENT AND THE HYPERPARAMETERS\r\n",
        "OF THE NEURAL NETWORK\"\"\"\r\n",
        "env=gym.make('reacher-v0')                                                      #declare the environment variable\r\n",
        "hu1=17                                                                          #size of the first hidden layer of the NN\r\n",
        "hu2=15                                                                          #size of the second hidden layer (if any) of the NN\r\n",
        "hu3=5                                                                           #size of the third hidden layer (if any) of the NN\r\n",
        "gamma=.999                                                                      #the discount factor\r\n",
        "maxIterations=2000                                                              #maximum iterations\r\n",
        "seed=8                                                                          #random seed used for random initialization of the network weights, the environment and various random function\r\n",
        "sigma=.5                                                                        #initial standard deviation for perturbing θ\r\n",
        "mean=.01                                                                        #initial mean for perturbing θ\r\n",
        "n=300                                                                           ##perturbations of θ\r\n",
        "k=5                                                                             #select the best k% θi from θ\r\n",
        "meanReward100=env.spec.reward_threshold                                         #mean reward earned over the last 100 episodes\r\n",
        "observations=env.observation_space.shape[0]                                     ##observations or I/P features\r\n",
        "actions=env.action_space.n                                                      #actions\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"CEM\"\"\"\r\n",
        "env.seed(seed)                                                                  #set the seed for the environment\r\n",
        "agent=CEMagent(observations,actions,hu1,hu2,hu3)                                #create an object of type 'CEMagent'\r\n",
        "results,model=agent.train(env,seed,mean,sigma,gamma,n,k,maxIterations)          #train the CEM agent\r\n",
        "save_checkpoint(model,'model1',1)                                               #save the model in Google Drive\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"PLOT THE RESULTS\"\"\"\r\n",
        "trainResults=np.array(results)\r\n",
        "numIterations=trainResults[:,0]                                                 #total #iterations\r\n",
        "numSteps=trainResults[:,1]                                                      #total #time-steps\r\n",
        "meanEvalScore=trainResults[:,3]                                                 #mean evaluation score\r\n",
        "\r\n",
        "figure1=plt.figure()                                                            #plot the #iterations\r\n",
        "axis1=figure1.add_subplot(111)\r\n",
        "plt.plot(numIterations,meanEvalScore,linewidth=2)\r\n",
        "plt.ylabel('Mean evaluation score')\r\n",
        "plt.xlabel('#iterations')\r\n",
        "axis1.set_title('Mean evaluation score v/s #iterations')\r\n",
        "\r\n",
        "figure2=plt.figure()                                                            #plot the #time-steps\r\n",
        "axis2=figure2.add_subplot(111)\r\n",
        "plt.plot(numSteps,meanEvalScore,linewidth=2)\r\n",
        "plt.ylabel('Mean evaluation score')\r\n",
        "plt.xlabel('#time-steps')\r\n",
        "axis2.set_title('Mean evaluation score v/s #time-steps')\r\n",
        "\r\n",
        "figure3=plt.figure()                                                            #plot the #time-steps versus #episodes\r\n",
        "axis3=figure3.add_subplot(111)\r\n",
        "plt.plot(numIterations,numSteps,linewidth=2)\r\n",
        "plt.xlabel('#iterations')\r\n",
        "plt.ylabel('#time-steps')\r\n",
        "axis3.set_title('#time-steps v/s #iterations')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:77: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration#: 1\tStep#: 4897\tEvaluation reward: -0.30\tMean evaluation reward: -0.30\tSTD of evaluation reward: 0.00\n",
            "Iteration#: 2\tStep#: 10873\tEvaluation reward: -0.30\tMean evaluation reward: -0.30\tSTD of evaluation reward: 0.00\n",
            "Iteration#: 3\tStep#: 14996\tEvaluation reward: -0.30\tMean evaluation reward: -0.30\tSTD of evaluation reward: 0.00\n",
            "Iteration#: 4\tStep#: 18801\tEvaluation reward: 0.04\tMean evaluation reward: -0.22\tSTD of evaluation reward: 0.14\n",
            "Iteration#: 5\tStep#: 25828\tEvaluation reward: 0.04\tMean evaluation reward: -0.16\tSTD of evaluation reward: 0.16\n",
            "Iteration#: 6\tStep#: 33003\tEvaluation reward: -0.31\tMean evaluation reward: -0.19\tSTD of evaluation reward: 0.16\n",
            "Iteration#: 7\tStep#: 41429\tEvaluation reward: 0.05\tMean evaluation reward: -0.15\tSTD of evaluation reward: 0.17\n",
            "Iteration#: 8\tStep#: 50841\tEvaluation reward: -0.31\tMean evaluation reward: -0.17\tSTD of evaluation reward: 0.17\n",
            "Iteration#: 9\tStep#: 61510\tEvaluation reward: 1.41\tMean evaluation reward: 0.00\tSTD of evaluation reward: 0.52\n",
            "Iteration#: 10\tStep#: 73804\tEvaluation reward: 1.42\tMean evaluation reward: 0.14\tSTD of evaluation reward: 0.65\n",
            "Iteration#: 11\tStep#: 84832\tEvaluation reward: 1.38\tMean evaluation reward: 0.26\tSTD of evaluation reward: 0.71\n",
            "Iteration#: 12\tStep#: 95973\tEvaluation reward: 1.42\tMean evaluation reward: 0.35\tSTD of evaluation reward: 0.76\n",
            "Iteration#: 13\tStep#: 106011\tEvaluation reward: 1.38\tMean evaluation reward: 0.43\tSTD of evaluation reward: 0.78\n",
            "Iteration#: 14\tStep#: 116119\tEvaluation reward: 1.42\tMean evaluation reward: 0.50\tSTD of evaluation reward: 0.79\n",
            "Iteration#: 15\tStep#: 126751\tEvaluation reward: 1.42\tMean evaluation reward: 0.56\tSTD of evaluation reward: 0.80\n",
            "Iteration#: 16\tStep#: 138288\tEvaluation reward: 1.42\tMean evaluation reward: 0.62\tSTD of evaluation reward: 0.80\n",
            "Iteration#: 17\tStep#: 150255\tEvaluation reward: 1.42\tMean evaluation reward: 0.66\tSTD of evaluation reward: 0.80\n",
            "Iteration#: 18\tStep#: 161631\tEvaluation reward: 1.42\tMean evaluation reward: 0.71\tSTD of evaluation reward: 0.79\n",
            "Iteration#: 19\tStep#: 173991\tEvaluation reward: 1.42\tMean evaluation reward: 0.74\tSTD of evaluation reward: 0.79\n",
            "Iteration#: 20\tStep#: 185631\tEvaluation reward: 1.42\tMean evaluation reward: 0.78\tSTD of evaluation reward: 0.78\n",
            "Iteration#: 21\tStep#: 193948\tEvaluation reward: 1.42\tMean evaluation reward: 0.81\tSTD of evaluation reward: 0.78\n",
            "Iteration#: 22\tStep#: 200890\tEvaluation reward: 1.42\tMean evaluation reward: 0.84\tSTD of evaluation reward: 0.77\n",
            "Iteration#: 23\tStep#: 209796\tEvaluation reward: 1.42\tMean evaluation reward: 0.86\tSTD of evaluation reward: 0.76\n",
            "Iteration#: 24\tStep#: 215820\tEvaluation reward: 1.42\tMean evaluation reward: 0.88\tSTD of evaluation reward: 0.75\n",
            "Iteration#: 25\tStep#: 222884\tEvaluation reward: 1.42\tMean evaluation reward: 0.91\tSTD of evaluation reward: 0.75\n",
            "Iteration#: 26\tStep#: 227376\tEvaluation reward: 1.42\tMean evaluation reward: 0.93\tSTD of evaluation reward: 0.74\n",
            "Iteration#: 27\tStep#: 231334\tEvaluation reward: 1.42\tMean evaluation reward: 0.94\tSTD of evaluation reward: 0.73\n",
            "Iteration#: 28\tStep#: 235898\tEvaluation reward: 1.42\tMean evaluation reward: 0.96\tSTD of evaluation reward: 0.72\n",
            "Iteration#: 29\tStep#: 240608\tEvaluation reward: 1.42\tMean evaluation reward: 0.98\tSTD of evaluation reward: 0.71\n",
            "Iteration#: 30\tStep#: 245236\tEvaluation reward: 1.42\tMean evaluation reward: 0.99\tSTD of evaluation reward: 0.71\n",
            "Iteration#: 31\tStep#: 249508\tEvaluation reward: 1.42\tMean evaluation reward: 1.00\tSTD of evaluation reward: 0.70\n",
            "Iteration#: 32\tStep#: 254050\tEvaluation reward: 1.42\tMean evaluation reward: 1.02\tSTD of evaluation reward: 0.69\n",
            "Iteration#: 33\tStep#: 257982\tEvaluation reward: 1.42\tMean evaluation reward: 1.03\tSTD of evaluation reward: 0.69\n",
            "Iteration#: 34\tStep#: 261936\tEvaluation reward: 1.42\tMean evaluation reward: 1.04\tSTD of evaluation reward: 0.68\n",
            "Iteration#: 35\tStep#: 265832\tEvaluation reward: 1.42\tMean evaluation reward: 1.05\tSTD of evaluation reward: 0.67\n",
            "Iteration#: 36\tStep#: 269718\tEvaluation reward: 1.42\tMean evaluation reward: 1.06\tSTD of evaluation reward: 0.66\n",
            "Iteration#: 37\tStep#: 273602\tEvaluation reward: 1.42\tMean evaluation reward: 1.07\tSTD of evaluation reward: 0.66\n",
            "Iteration#: 38\tStep#: 277478\tEvaluation reward: 1.42\tMean evaluation reward: 1.08\tSTD of evaluation reward: 0.65\n",
            "Iteration#: 39\tStep#: 281307\tEvaluation reward: 1.42\tMean evaluation reward: 1.09\tSTD of evaluation reward: 0.65\n",
            "Iteration#: 40\tStep#: 285134\tEvaluation reward: 1.42\tMean evaluation reward: 1.10\tSTD of evaluation reward: 0.64\n",
            "Iteration#: 41\tStep#: 288970\tEvaluation reward: 1.42\tMean evaluation reward: 1.11\tSTD of evaluation reward: 0.63\n",
            "Iteration#: 42\tStep#: 292870\tEvaluation reward: 1.42\tMean evaluation reward: 1.11\tSTD of evaluation reward: 0.63\n",
            "Iteration#: 43\tStep#: 296770\tEvaluation reward: 1.42\tMean evaluation reward: 1.12\tSTD of evaluation reward: 0.62\n",
            "Iteration#: 44\tStep#: 300672\tEvaluation reward: 1.42\tMean evaluation reward: 1.13\tSTD of evaluation reward: 0.62\n",
            "Iteration#: 45\tStep#: 304564\tEvaluation reward: 1.42\tMean evaluation reward: 1.13\tSTD of evaluation reward: 0.61\n",
            "Iteration#: 46\tStep#: 308464\tEvaluation reward: 1.42\tMean evaluation reward: 1.14\tSTD of evaluation reward: 0.61\n",
            "Iteration#: 47\tStep#: 312368\tEvaluation reward: 1.42\tMean evaluation reward: 1.15\tSTD of evaluation reward: 0.60\n",
            "Iteration#: 48\tStep#: 316268\tEvaluation reward: 1.42\tMean evaluation reward: 1.15\tSTD of evaluation reward: 0.60\n",
            "Iteration#: 49\tStep#: 320168\tEvaluation reward: 1.42\tMean evaluation reward: 1.16\tSTD of evaluation reward: 0.59\n",
            "Iteration#: 50\tStep#: 324068\tEvaluation reward: 1.42\tMean evaluation reward: 1.16\tSTD of evaluation reward: 0.59\n",
            "Iteration#: 51\tStep#: 327968\tEvaluation reward: 1.42\tMean evaluation reward: 1.17\tSTD of evaluation reward: 0.58\n",
            "Iteration#: 52\tStep#: 331868\tEvaluation reward: 1.42\tMean evaluation reward: 1.17\tSTD of evaluation reward: 0.58\n",
            "Iteration#: 53\tStep#: 335768\tEvaluation reward: 1.42\tMean evaluation reward: 1.18\tSTD of evaluation reward: 0.57\n",
            "Iteration#: 54\tStep#: 339668\tEvaluation reward: 1.42\tMean evaluation reward: 1.18\tSTD of evaluation reward: 0.57\n",
            "Iteration#: 55\tStep#: 343574\tEvaluation reward: 1.42\tMean evaluation reward: 1.19\tSTD of evaluation reward: 0.56\n",
            "Iteration#: 56\tStep#: 347476\tEvaluation reward: 1.42\tMean evaluation reward: 1.19\tSTD of evaluation reward: 0.56\n",
            "Iteration#: 57\tStep#: 351386\tEvaluation reward: 1.42\tMean evaluation reward: 1.19\tSTD of evaluation reward: 0.56\n",
            "Iteration#: 58\tStep#: 355296\tEvaluation reward: 1.42\tMean evaluation reward: 1.20\tSTD of evaluation reward: 0.55\n",
            "Iteration#: 59\tStep#: 359210\tEvaluation reward: 1.42\tMean evaluation reward: 1.20\tSTD of evaluation reward: 0.55\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '#time-steps v/s #iterations')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsQjRylTnYPf"
      },
      "source": [
        "###Test the policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "GY6KMtbR-rRq",
        "outputId": "2f3ee5d7-962d-433a-b94e-7c0ec3fa0f88"
      },
      "source": [
        "\"\"\"TESTING\"\"\"\r\n",
        "env=gym.make('reacher-v0')\r\n",
        "env=Monitor(env,'./video',force=True,video_callable=lambda episode:True)\r\n",
        "#env.seed(10)\r\n",
        "s=env.reset()\r\n",
        "terminal=False\r\n",
        "episodeReward=0\r\n",
        "while not terminal:\r\n",
        "  s=torch.tensor(s).float().to(device)\r\n",
        "  a=agent.greedy(s)\r\n",
        "  s,r,terminal,info=env.step(a)\r\n",
        "  episodeReward+=r\r\n",
        "env.close()\r\n",
        "print('\\nEpisode reward:'+str(episodeReward))\r\n",
        "show_video('./video')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Origin:  [0.0, 0.0]\n",
            "world_width:  50.0\n",
            "world_height:  50.0\n",
            "Screen:  <Surface(600x600x32 SW)>\n",
            "\n",
            "Episode reward:1.4336206947403212\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video alt=\"video/openaigym.video.13.60.video000000.mp4\" autoplay \n",
              "                      controls style=\"height: 400px;\">\n",
              "                      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "                 </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3hmSsvaneTC"
      },
      "source": [
        "###Q2. Evolution Strategy Salimas et al. 2017\r\n",
        "Implement below the non-distributed version of the evolution strategies method from  [[Salimans et al., 2017]](https://arxiv.org/pdf/1703.03864.pdf) to solve the LunarLanderContinuous-v2 environment and enable the agent to navigate to its landing pad. Please, refer to the project descriprtion and lecture 13 for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3vLzI-gEMis"
      },
      "source": [
        "First, let's test the new environment out!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bzgv9jsEPsp"
      },
      "source": [
        "display=Display(visible=0,size=(900,400))\r\n",
        "display.start()\r\n",
        "\r\n",
        "env=gym.make(\"LunarLanderContinuous-v2\")\r\n",
        "env=Monitor(env,'./video',force=True,video_callable=lambda episode:True)\r\n",
        "env.reset()\r\n",
        "done=False\r\n",
        "while not done:\r\n",
        "  action=env.action_space.sample()\r\n",
        "  obs,reward,done,info=env.step(action)\r\n",
        "env.close()\r\n",
        "show_video('./video')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbrwnXj4EVRH"
      },
      "source": [
        "The observation that the agent receives is its position, velocity, angular speed, and two 2 Boolean flags indicating whether the left and right leg of the agent, respectively, is in contact with the ground.\r\n",
        "\r\n",
        "Two continuous actions are used to control the agent. The first one controls the main engine and the second one controls the left and right engines. *The expected range of each of the two actions is [-1, 1]. Please make sure that your policy network outputs values in that range*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "849urNIfEWM5"
      },
      "source": [
        "print('observation space:',env.observation_space)\r\n",
        "print('action space:',env.action_space)\r\n",
        "print('solved_score',env.spec.reward_threshold)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE27boN9EbVr"
      },
      "source": [
        "### Implement a policy network that the agent can use to select actions. \r\n",
        "Instead of training the parameters of the network, you will directly set them based on your ES optimization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPRzTMRmoQBO"
      },
      "source": [
        "\"\"\"SWITCH TO A GPU IF ONE IS AVAILABLE\"\"\"\r\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"DEFINITION OF THE ARCHITECTURE AND THE ATTRIBUTES OF THE NEURAL NETWORK\"\"\"\r\n",
        "class network2(nn.Module):\r\n",
        "  def __init__(self,observations,actions,hu1,hu2,hu3=2):\r\n",
        "    super(network2, self).__init__()\r\n",
        "    self.l1=nn.Linear(observations,hu1)                                         #layer1 is a fully-connected layer with #I/P=observations and #hidden units=hu1\r\n",
        "    self.l2=nn.Linear(hu1,hu2)                                                  #layer2 is a fully-connected layer with #I/P=hu1 and #hidden units=hu2\r\n",
        "    self.l3=nn.Linear(hu2,actions)                                              #layer3 is a fully-connected layer with #I/P=hu2 and #units=actions\r\n",
        "\r\n",
        "  def forward(self,x):                                                          #forward propagation function\r\n",
        "    if not isinstance(x,torch.Tensor):                                          #check if the I/P is a tensor or not\r\n",
        "      x=torch.tensor(x,device=device,dtype=torch.float32)                       #convert the I/P to a tensor and move it to 'device'\r\n",
        "      x=x.unsqueeze(0)\r\n",
        "    x=torch.tanh(self.l1(x))\r\n",
        "    x=torch.tanh(self.l2(x))\r\n",
        "    x=torch.tanh(self.l3(x))\r\n",
        "    return x\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"DEFINITION OF THE CHARACTERISTICS AND ATTRIBUTES OF THE CEM AGENT\"\"\"\r\n",
        "class ESagent():\r\n",
        "  def __init__(self,observations,actions,hu1,hu2):\r\n",
        "    self.policynet=network2(observations,actions,hu1,hu2).to(device)            #define a policy-network object of type 'network2', initialize its weights θ randomly and move it to the GPU\r\n",
        "    self.tempnet=network2(observations,actions,hu1,hu2).to(device)              #define a dummy netowrk object of type 'network2', initialize its weights θ randomly and move it to the GPU\r\n",
        "\r\n",
        "  def train(self,env,seed,alpha,momentum,sigma,gamma,n,maxIterations):\r\n",
        "    self.alpha=alpha\r\n",
        "    self.momentum=momentum\r\n",
        "    self.gamma=gamma\r\n",
        "    self.sigma=sigma\r\n",
        "    self.steps=0\r\n",
        "    self.dimension=sum(p.numel() for p in self.policynet.parameters())\r\n",
        "    torch.manual_seed(seed) \r\n",
        "    np.random.seed(seed)\r\n",
        "    random.seed(seed)\r\n",
        "    env.seed(seed)\r\n",
        "    self.evalScoreIteration=[]\r\n",
        "    self.results=[]\r\n",
        "    iterations=0\r\n",
        "    while iterations<maxIterations:\r\n",
        "      iterations+=1\r\n",
        "      theta_is=[]\r\n",
        "      noise_is=[]\r\n",
        "      for i in range(n):                                                        #run this loop 'n' times to collect 'n' perturbations of θ\r\n",
        "        theta_i,noise_i=self.perturbations()\r\n",
        "        theta_is.append(theta_i)\r\n",
        "        noise_is.append(noise_i)\r\n",
        "      G_is=self.rollOut(env,theta_is)                                           #call this function to perform a roll-out corresponding to each θ, and calculate the corresponding reward R(τi)\r\n",
        "      self.weightUpdate(G_is,noise_is,n)                                        #update the weights of the policy network using the ide\r\n",
        "      evalScore=self.evaluate(env)                                              #perform a roll-out after each round of weight update            \r\n",
        "      self.evalScoreIteration.append(evalScore)      \r\n",
        "      print('Iteration#: {:d}\\tStep#: {:d}\\tEvaluation reward: {:.2f}\\t\\u03BC evaluation reward: {:.2f}\\t\\u03C3 of evaluation reward: {:.2f}\\t\\u03BC\\u2085\\u2080 evaluation reward: {:.2f}'.format(iterations,self.steps,evalScore,np.mean(self.evalScoreIteration),np.std(self.evalScoreIteration),np.mean(self.evalScoreIteration[-50:])))\r\n",
        "      self.results.append((iterations,self.steps,evalScore,np.mean(self.evalScoreIteration),np.std(self.evalScoreIteration),np.mean(self.evalScoreIteration[-50:])))\r\n",
        "      if np.mean(self.evalScoreIteration[-50:])>=100.0 and iterations!=1:\r\n",
        "        break\r\n",
        "    return self.results,self.policynet\r\n",
        "\r\n",
        "  def perturbations(self):\r\n",
        "    temp=torch.cat([parameter.view(-1) for parameter in self.policynet.parameters()])\r\n",
        "    noise=self.sigma*torch.randn(self.dimension).to(device)\r\n",
        "    perturbation=temp+noise\r\n",
        "    return perturbation,noise\r\n",
        "\r\n",
        "  def rollOut(self,env,theta_is):\r\n",
        "    R=[]                                                                        #list stores R(τi) of each τi\r\n",
        "    temp=self.tempnet.state_dict()\r\n",
        "    for i in theta_is:\r\n",
        "      theta_i=torch.tensor(i).to(device)\r\n",
        "      lLimit,hLimit=0,0\r\n",
        "      for label,parameter in zip(temp,self.tempnet.parameters()):               #iterate over each label of 'temp' and each parameter of the policy network\r\n",
        "        hLimit=lLimit+sum(p.numel() for p in temp[label])\r\n",
        "        temp[label]=torch.reshape(theta_i[lLimit:hLimit],temp[label].size())    #generate a perturbation of the current parameter using the expression θ=θ+σε\r\n",
        "        lLimit=hLimit\r\n",
        "      self.tempnet.load_state_dict(temp)\r\n",
        "      terminal=False\r\n",
        "      numExperiences=0\r\n",
        "      s=env.reset()\r\n",
        "      R.append(0.0)\r\n",
        "      while not terminal:\r\n",
        "        self.steps+=1\r\n",
        "        s=torch.tensor(s).type(torch.FloatTensor).to(device)\r\n",
        "        with torch.no_grad():\r\n",
        "          Q=self.tempnet(s).cpu().detach().data.numpy().squeeze()\r\n",
        "        action=Q\r\n",
        "        sP,r,terminal,info=env.step(action)\r\n",
        "        s=sP\r\n",
        "        numExperiences+=1\r\n",
        "        R[-1]+=(self.gamma**(numExperiences-1))*r                               #sum of discounted rewards of the current trajectory\r\n",
        "    return R\r\n",
        "\r\n",
        "  def weightUpdate(self,G_is,noise_is,n):                                       #this function updates the weights of the policy network\r\n",
        "    temp=self.policynet.state_dict()                                            #create a copy of the weights of the policy network\r\n",
        "    update=torch.zeros(self.dimension).to(device)\r\n",
        "    G_is=np.array(G_is)\r\n",
        "    G_is=((G_is-np.mean(G_is))/np.std(G_is)).tolist()\r\n",
        "    for i in range(n):\r\n",
        "      update+=G_is[i]*noise_is[i]\r\n",
        "    update*=((self.momentum*self.alpha)/(n*self.sigma))\r\n",
        "    lLimit,hLimit=0,0\r\n",
        "    for label in temp:\r\n",
        "      hLimit=lLimit+sum(p.numel() for p in temp[label])\r\n",
        "      temp[label]+=torch.reshape(update[lLimit:hLimit],temp[label].size())\r\n",
        "      lLimit=hLimit\r\n",
        "    self.policynet.load_state_dict(temp)\r\n",
        "\r\n",
        "  def evaluate(self,env,rollOuts=1):                                            #this function performs a fixed #roll-outs at the end of each training episode and evaluates the associated rewards\r\n",
        "    rewards=[]\r\n",
        "    for rollOut in range(rollOuts):\r\n",
        "      rewards.append(0.0)\r\n",
        "      s1=env.reset()\r\n",
        "      terminal1=False\r\n",
        "      numExperiences=0\r\n",
        "      while not terminal1:\r\n",
        "        s1=torch.tensor(s1).float().to(device)\r\n",
        "        a1=self.greedy(s1)\r\n",
        "        s1,r1,terminal1,info1=env.step(a1)\r\n",
        "        numExperiences+=1\r\n",
        "        rewards[-1]+=(self.gamma**(numExperiences-1))*r1\r\n",
        "    return np.mean(rewards)\r\n",
        "\r\n",
        "  def greedy(self,s):                                                           #this function returns the action that is greedy wrt to the Q-values of the state 's'\r\n",
        "    with torch.no_grad():\r\n",
        "      Q=self.policynet(s)\r\n",
        "    Q=Q.cpu().numpy()\r\n",
        "    return Q\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"DEFINE THE ENVIRONMENT, THE PARAMETERS OF THE AGENT AND THE HYPERPARAMETERS\r\n",
        "OF THE NEURAL NETWORK\"\"\"\r\n",
        "env=gym.make('LunarLanderContinuous-v2')                                        #declare the environment variable\r\n",
        "hu1=30                                                                          #size of the first hidden layer of the NN\r\n",
        "hu2=30                                                                          #size of the second hidden layer of the NN\r\n",
        "gamma=0.999                                                                     #the discount factor\r\n",
        "maxIterations=500                                                              #maximum iterations for which is θ updated\r\n",
        "seed=1                                                                          #random seed used for random initialization of the network weights, the environment and various random function\r\n",
        "sigma=.1                                                                        #standard deviation for perturbing θ\r\n",
        "alpha=0.3                                                                      #the learning rate\r\n",
        "momentum=1\r\n",
        "n=50                                                                            ##perturbations of θ\r\n",
        "observations=env.observation_space.shape[0]                                     ##observations or I/P features\r\n",
        "actions=2                                                                       ##continuous actions\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"ES\"\"\"\r\n",
        "env.seed(seed)                                                                  #set the seed for the environment\r\n",
        "agent=ESagent(observations,actions,hu1,hu2)                                     #create an object of type 'ESagent'\r\n",
        "results,model=agent.train(env,seed,alpha,momentum,sigma,gamma,n,maxIterations)\r\n",
        "save_checkpoint(model,'model2',1)                                               #save the model in Google Drive\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"PLOT THE RESULTS\"\"\"\r\n",
        "trainResults=np.array(results)\r\n",
        "numIterations=trainResults[:,0]                                                 #total #iterations\r\n",
        "numSteps=trainResults[:,1]                                                      #total #time-steps\r\n",
        "meanEvalScore=trainResults[:,3]                                                 #mean evaluation score of all evaluations\r\n",
        "meanEvalScore50=trainResults[:,5]                                               #mean evaluation score for last 50 evaluations\r\n",
        "\r\n",
        "figure1=plt.figure()                                                            #plot mean evaluation score against #iterations\r\n",
        "axis1=figure1.add_subplot(111)\r\n",
        "plt.plot(numIterations,meanEvalScore,linewidth=2)\r\n",
        "plt.ylabel('Mean evaluation score')\r\n",
        "plt.xlabel('#iterations')\r\n",
        "axis1.set_title('Mean evaluation score v/s #iterations')\r\n",
        "\r\n",
        "figure2=plt.figure()                                                            #plot mean evaluation score against #time-steps\r\n",
        "axis2=figure2.add_subplot(111)\r\n",
        "plt.plot(numSteps,meanEvalScore,linewidth=2)\r\n",
        "plt.ylabel('Mean evaluation score')\r\n",
        "plt.xlabel('#time-steps')\r\n",
        "axis2.set_title('Mean evaluation score v/s #time-steps')\r\n",
        "\r\n",
        "figure3=plt.figure()                                                            #plot the #time-steps versus #episodes\r\n",
        "axis3=figure3.add_subplot(111)\r\n",
        "plt.plot(numIterations,numSteps,linewidth=2)\r\n",
        "plt.xlabel('#iterations')\r\n",
        "plt.ylabel('#time-steps')\r\n",
        "axis3.set_title('#time-steps v/s #iterations')\r\n",
        "\r\n",
        "figure4=plt.figure()                                                            #plot mean evaluation score for last 50 evaluations against #iterations\r\n",
        "axis4=figure4.add_subplot(111)\r\n",
        "plt.plot(numIterations,meanEvalScore50,linewidth=2)\r\n",
        "plt.xlabel('#iterations')\r\n",
        "plt.ylabel('Mean evaluation score')\r\n",
        "axis4.set_title('Mean evaluation score for last 50 evaluations v/s #iterations')\r\n",
        "\r\n",
        "figure5=plt.figure()                                                            #plot mean evaluation score for last 50 evaluations against #time-steps\r\n",
        "axis5=figure5.add_subplot(111)\r\n",
        "plt.plot(numSteps,meanEvalScore50,linewidth=2)\r\n",
        "plt.xlabel('#time-steps')\r\n",
        "plt.ylabel('Mean evaluation score')\r\n",
        "axis5.set_title('Mean evaluation score for last 50 evaluations v/s #time-steps')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QfzIdjBXK0K"
      },
      "source": [
        "Consolidated results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwkdTyABUgsO",
        "outputId": "9bbf7b69-6177-4472-83d1-74b8b2c79ebe"
      },
      "source": [
        "env.seed(1)                                                                  #set the seed for the environment\r\n",
        "agent=ESagent(observations,actions,hu1,hu2) \r\n",
        "results1,model=agent.train(env,1,alpha,momentum,sigma,gamma,n,maxIterations)\r\n",
        "env.seed(6)                                                                  #set the seed for the environment\r\n",
        "agent=ESagent(observations,actions,hu1,hu2) \r\n",
        "results6,model=agent.train(env,6,alpha,momentum,sigma,gamma,n,maxIterations)\r\n",
        "env.seed(25)                                                                  #set the seed for the environment\r\n",
        "agent=ESagent(observations,actions,hu1,hu2) \r\n",
        "results25,model=agent.train(env,25,alpha,momentum,sigma,gamma,n,maxIterations)\r\n",
        "\r\n",
        "\r\n",
        "\"\"\"PLOT THE RESULTS\"\"\"\r\n",
        "trainResults1=np.array(results1)\r\n",
        "numIterations1=trainResults1[:,0]                                                 #total #iterations\r\n",
        "numSteps1=trainResults1[:,1]                                                      #total #time-steps\r\n",
        "meanEvalScore1=trainResults1[:,3]                                                 #mean evaluation score of all evaluations\r\n",
        "trainResults6=np.array(results6)\r\n",
        "numIterations6=trainResults6[:,0]                                                 #total #iterations\r\n",
        "numSteps6=trainResults6[:,1]                                                      #total #time-steps\r\n",
        "meanEvalScore6=trainResults6[:,3]                                                 #mean evaluation score of all evaluations\r\n",
        "trainResults25=np.array(results25)\r\n",
        "numIterations25=trainResults25[:,0]                                                 #total #iterations\r\n",
        "numSteps25=trainResults25[:,1]                                                      #total #time-steps\r\n",
        "meanEvalScore25=trainResults25[:,3]                                                 #mean evaluation score of all evaluations\r\n",
        "\r\n",
        "\r\n",
        "figure1=plt.figure()                                                            #plot mean evaluation score against #iterations\r\n",
        "axis1=figure1.add_subplot(111)\r\n",
        "plt.hold('True')\r\n",
        "plt.plot(numIterations1,meanEvalScore1,'b',label='Seed 1',linewidth=2)\r\n",
        "plt.plot(numIterations6,meanEvalScore6,'g',label='Seed 6',linewidth=2)\r\n",
        "plt.plot(numIterations25,meanEvalScore25,'r',label='Seed 25',linewidth=2)\r\n",
        "plt.legend(loc=\"upper left\")\r\n",
        "plt.ylabel('Mean evaluation score')\r\n",
        "plt.xlabel('#iterations')\r\n",
        "axis1.set_title('Mean evaluation score v/s #iterations')\r\n",
        "\r\n",
        "figure2=plt.figure()                                                            #plot mean evaluation score against #time-steps\r\n",
        "axis2=figure2.add_subplot(111)\r\n",
        "plt.hold('True')\r\n",
        "plt.plot(numSteps1,meanEvalScore1,'b',label='Seed 1',linewidth=2)\r\n",
        "plt.plot(numSteps6,meanEvalScore6,'g',label='Seed 6',linewidth=2)\r\n",
        "plt.plot(numSteps25,meanEvalScore25,'r',label='Seed 25',linewidth=2)\r\n",
        "plt.legend(loc=\"upper left\")\r\n",
        "plt.ylabel('Mean evaluation score')\r\n",
        "plt.xlabel('#time-steps')\r\n",
        "axis2.set_title('Mean evaluation score v/s #time-steps')\r\n",
        "\r\n",
        "figure3=plt.figure()                                                            #plot the #time-steps versus #episodes\r\n",
        "axis3=figure3.add_subplot(111)\r\n",
        "plt.hold('True')\r\n",
        "plt.plot(numIterations1,numSteps1,'b',label='Seed 1',linewidth=2)\r\n",
        "plt.plot(numIterations6,numSteps6,'g',label='Seed 6',linewidth=2)\r\n",
        "plt.plot(numIterations25,numSteps25,'r',label='Seed 25',linewidth=2)\r\n",
        "plt.legend(loc=\"upper left\")\r\n",
        "plt.xlabel('#iterations')\r\n",
        "plt.ylabel('#time-steps')\r\n",
        "axis3.set_title('#time-steps v/s #iterations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration#: 1\tStep#: 4342\tEvaluation reward: -131.05\tμ evaluation reward: -131.05\tσ of evaluation reward: 0.00\tμ₅₀ evaluation reward: -131.05\n",
            "Iteration#: 2\tStep#: 8371\tEvaluation reward: -120.16\tμ evaluation reward: -125.60\tσ of evaluation reward: 5.45\tμ₅₀ evaluation reward: -125.60\n",
            "Iteration#: 3\tStep#: 12446\tEvaluation reward: -102.53\tμ evaluation reward: -117.91\tσ of evaluation reward: 11.75\tμ₅₀ evaluation reward: -117.91\n",
            "Iteration#: 4\tStep#: 15979\tEvaluation reward: -107.17\tμ evaluation reward: -115.23\tσ of evaluation reward: 11.19\tμ₅₀ evaluation reward: -115.23\n",
            "Iteration#: 5\tStep#: 19607\tEvaluation reward: -117.82\tμ evaluation reward: -115.75\tσ of evaluation reward: 10.06\tμ₅₀ evaluation reward: -115.75\n",
            "Iteration#: 6\tStep#: 23163\tEvaluation reward: -159.43\tμ evaluation reward: -123.03\tσ of evaluation reward: 18.69\tμ₅₀ evaluation reward: -123.03\n",
            "Iteration#: 7\tStep#: 26660\tEvaluation reward: -124.38\tμ evaluation reward: -123.22\tσ of evaluation reward: 17.31\tμ₅₀ evaluation reward: -123.22\n",
            "Iteration#: 8\tStep#: 30364\tEvaluation reward: -88.40\tμ evaluation reward: -118.87\tσ of evaluation reward: 19.87\tμ₅₀ evaluation reward: -118.87\n",
            "Iteration#: 9\tStep#: 33930\tEvaluation reward: -108.77\tμ evaluation reward: -117.75\tσ of evaluation reward: 19.00\tμ₅₀ evaluation reward: -117.75\n",
            "Iteration#: 10\tStep#: 37436\tEvaluation reward: -137.79\tμ evaluation reward: -119.75\tσ of evaluation reward: 19.00\tμ₅₀ evaluation reward: -119.75\n",
            "Iteration#: 11\tStep#: 41035\tEvaluation reward: -104.72\tμ evaluation reward: -118.39\tσ of evaluation reward: 18.63\tμ₅₀ evaluation reward: -118.39\n",
            "Iteration#: 12\tStep#: 44632\tEvaluation reward: -127.94\tμ evaluation reward: -119.18\tσ of evaluation reward: 18.03\tμ₅₀ evaluation reward: -119.18\n",
            "Iteration#: 13\tStep#: 48026\tEvaluation reward: -148.84\tμ evaluation reward: -121.46\tσ of evaluation reward: 19.04\tμ₅₀ evaluation reward: -121.46\n",
            "Iteration#: 14\tStep#: 51708\tEvaluation reward: -155.03\tμ evaluation reward: -123.86\tσ of evaluation reward: 20.28\tμ₅₀ evaluation reward: -123.86\n",
            "Iteration#: 15\tStep#: 55304\tEvaluation reward: -194.70\tμ evaluation reward: -128.58\tσ of evaluation reward: 26.38\tμ₅₀ evaluation reward: -128.58\n",
            "Iteration#: 16\tStep#: 58711\tEvaluation reward: -147.20\tμ evaluation reward: -129.75\tσ of evaluation reward: 25.94\tμ₅₀ evaluation reward: -129.75\n",
            "Iteration#: 17\tStep#: 62241\tEvaluation reward: -144.25\tμ evaluation reward: -130.60\tσ of evaluation reward: 25.40\tμ₅₀ evaluation reward: -130.60\n",
            "Iteration#: 18\tStep#: 65800\tEvaluation reward: -129.31\tμ evaluation reward: -130.53\tσ of evaluation reward: 24.68\tμ₅₀ evaluation reward: -130.53\n",
            "Iteration#: 19\tStep#: 69584\tEvaluation reward: -125.89\tμ evaluation reward: -130.28\tσ of evaluation reward: 24.05\tμ₅₀ evaluation reward: -130.28\n",
            "Iteration#: 20\tStep#: 73040\tEvaluation reward: -112.72\tμ evaluation reward: -129.41\tσ of evaluation reward: 23.75\tμ₅₀ evaluation reward: -129.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2B6Z4wYuy8o"
      },
      "source": [
        "Test the policy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7p3_BzGrwc6"
      },
      "source": [
        "display=Display(visible=0,size=(900,400))\r\n",
        "display.start()\r\n",
        "\"\"\"TESTING\"\"\"\r\n",
        "env=gym.make(\"LunarLanderContinuous-v2\")\r\n",
        "env=Monitor(env,'./video',force=True,video_callable=lambda episode:True)\r\n",
        "#env.seed(10)\r\n",
        "s=env.reset()\r\n",
        "terminal=False\r\n",
        "episodeReward=0\r\n",
        "while not terminal:\r\n",
        "  s=torch.tensor(s).float().to(device)\r\n",
        "  action=agent.greedy(s)\r\n",
        "  #action=env.action_space.sample()\r\n",
        "  s,r,terminal,info=env.step(action)\r\n",
        "  episodeReward+=r\r\n",
        "env.close()\r\n",
        "print('\\nEpisode reward:'+str(episodeReward))\r\n",
        "show_video('./video')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}