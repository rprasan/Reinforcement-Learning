## Environment
We use the following environments to demonstrate how black-box techniques can directly optimize an agent's policies:
Environment 1: <br />
The first environment has a frogger-like agent that navigates to a fixed goal on a static highway map.
Environment 1: <br />
The second environment is LunarLanderContinuous-v2 from OpenAI gym, in which a spaceship-like agent navigates to its landing pad by controlling its main central engine and its two side engines. <br />

Environment 1: <br />
![](https://github.com/rprasan/Reinforcement-Learning/blob/main/Blackbox%20Optimization%20Techniques/Environment%201/Seed%201/Average%20Reward%20Versus%20Number%20of%20Iterations.png) <br />
![](https://github.com/rprasan/Reinforcement-Learning/blob/main/Blackbox%20Optimization%20Techniques/Environment%201/Seed%201/Average%20Reward%20Versus%20Number%20of%20Steps.png) <br />
![](https://github.com/rprasan/Reinforcement-Learning/blob/main/Blackbox%20Optimization%20Techniques/Environment%201/Seed%201/Number%20of%20Steps%20Versus%20Number%20of%20Iterations.png) <br />
![](https://github.com/rprasan/Reinforcement-Learning/blob/main/Blackbox%20Optimization%20Techniques/Environment%201/Seed%201/Test%20Video.gif) <br /><br />

Environment 2: <br />
![](https://github.com/rprasan/Reinforcement-Learning/blob/main/Blackbox%20Optimization%20Techniques/Environment%202/Seed%201/Average%20Reward%20Versus%20Number%20of%20Iterations.png) <br />
![](https://github.com/rprasan/Reinforcement-Learning/blob/main/Blackbox%20Optimization%20Techniques/Environment%202/Seed%201/Average%20Reward%20Versus%20Number%20of%20Steps.png) <br />
![](https://github.com/rprasan/Reinforcement-Learning/blob/main/Blackbox%20Optimization%20Techniques/Environment%202/Seed%201/Number%20of%20Steps%20Versus%20Number%20of%20Iterations.png) <br />
![](https://github.com/rprasan/Reinforcement-Learning/blob/main/Blackbox%20Optimization%20Techniques/Environment%202/Seed%201/Average%20Reward%20For%20Last%2050%20Evaluations%20Versus%20Number%20of%20Iterations.png) <br />
![](https://github.com/rprasan/Reinforcement-Learning/blob/main/Blackbox%20Optimization%20Techniques/Environment%202/Seed%201/Average%20Reward%20For%20Last%2050%20Evaluations%20Versus%20Number%20of%20Steps.png) <br />
![](https://github.com/rprasan/Reinforcement-Learning/blob/main/Blackbox%20Optimization%20Techniques/Environment%202/Average%20Reward%20Versus%20Number%20of%20Iterations.png) <br />
![](https://github.com/rprasan/Reinforcement-Learning/blob/main/Blackbox%20Optimization%20Techniques/Environment%202/Average%20Reward%20Versus%20Number%20of%20Steps.png) <br />
![](https://github.com/rprasan/Reinforcement-Learning/blob/main/Blackbox%20Optimization%20Techniques/Environment%202/Number%20of%20Steps%20Versus%20Number%20of%20Iterations.png) <br />
![](https://github.com/rprasan/Reinforcement-Learning/blob/main/Blackbox%20Optimization%20Techniques/Environment%202/Seed%201/Test%20Video.gif) <br /><br />
